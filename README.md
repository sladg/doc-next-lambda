# Deploying Next to Lambda
Summary of knowledge in regards to deploying NextJS to Amazon Lambdas.

_TL;DR: NextJS in standalone mode + [lwa layer](https://github.com/awslabs/aws-lambda-web-adapter) = deployment on Function URL._

## Problems

### Network adapter

NextJS expects normal HTTP request and response objects whilst AWS Lambda together with other AWS services provide event object. This incompatibility results in problematic translation of incoming data and results.

Resources and solutions:
- https://www.npmjs.com/package/serverless-http
- https://github.com/aws-samples/lwa-nextjs-response-streaming-example
- https://github.com/awslabs/aws-lambda-web-adapter
- build custom HTTP server which translates some methods to compatible ones

- [ ] TBD describe solution

### Cold starts
Next server takes quite a bit of time to fire-up at the beggining. Vercel is working 

- [ ] TBD describe solution, 

### Caching
Next uses variety of caches and different mechanisms to improve performance. This results in rather over-complicated config for CloudFront.
Additional problem comes from Lambda's non-writable storage. Next will try to cache (write it) sometimes, this operation can fail, but results in lost performance.

- [ ] TBD describe solution, exploring EFS.

### Binaries
Lambda's runtime (if we ignore containerized option), uses Amazon Linux (multiple version options). This results in some of the binaries being possibly incompatible compared in runtime as buildtime used different OS / architecture. This is mostly notable in Prisma as their binaries take quite a lot of space.

- [ ] TBD describe solution

### Size

Assets, chunks, bundles and other things generated by Next can take huge space. On a medium CRM-style projects, we can expect `node_modules` taking 100MB. `standalone` server taking around 5MB and static assets (typically located in `.next/static`) taking 25MB, additionally, `public` folder can contain rather large amount of assets as well. This means we cannot feasibly store statically generated assets inside Lambda as we would cross size limit rather quickly.

With this known, we need to route part of the traffic away from Next's server. To serve these files, we can use S3, however, we add complexity with new service type. Possible middle-ground would be using Docker container which has size up to 10G.

- [ ] TBD describe solution

## Knowledge
- One of the first topics on ISR in non-Vercel environment. Main outcome is Vercel providing guide with basics.
  <br/>
  https://github.com/vercel/next.js/discussions/19589

- Vercel's guide to self-hosting. Most limited to non-serverless and containerised applications. Useful information about `isrMemoryCacheSize`
  <br/>
  https://nextjs.org/docs/app/building-your-application/deploying#docker-image

- SAM template allowing Next on Lambda with streaming support. Primary infromation is env variable `AWS_LWA_INVOKE_MODE: response_stream` and `InvokeMode: RESPONSE_STREAM`.
  <br/>
  https://github.com/aws-samples/lwa-nextjs-response-streaming-example/blob/main/template.yaml

- Minimal example in Express showing how to use LWA outside of container, aka. in native runtime. This is implementable for NextJS.
  <br/>
  https://github.com/awslabs/aws-lambda-web-adapter/tree/main/examples/expressjs-zip

- OG pioneer of runing HTTP servers on Lambda.
  <br/>
  https://github.com/apparentorder/reweb

- Solution for deploying NextJS via CDK & SST. It prepares neat ZIPs to be uploaded to AWS as ready functions. Could be used with Terraform as well.
  <br/>
  https://github.com/sst/open-next

- CDK construct built on top of open-next. It's smaller and more straigh forward than SST.
  <br/>
  https://github.com/jetbridge/cdk-nextjs

- Benchmark of different coldstarts for different size of instance and code. TL;DR docker is on average faster than big native functions.
  <br/>
  https://mikhail.io/serverless/coldstarts/aws/

- Caching deep-dive for Next. Description of quite a few examples of what happens when.
  <br/>
  https://github.com/vercel/next.js/discussions/54075
  

## Testing and benchmarks

Next 13.5 takes 800-900ms to initialise in Lambda native Node environment (very similar result for Alpine container on Lambda). This happens once-per-instance, meaning, this instance can deal with multiple requests without re-starting. Increased load on application will result in spin-up of multiple new instances, each taking this time to start.

<img width="712" alt="image" src="https://github.com/sladg/doc-next-lambda/assets/26263265/cc2d494e-8bad-4679-a500-5690e411f454">

